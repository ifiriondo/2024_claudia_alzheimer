{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import openpyxl\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXW8F1QCHK04SSYT740CBXQ8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY2PSK7T8CP2ESDN6YG4GGTE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory for the data\n",
    "results_dir = 'C:/Users/ifiri/Documents/PROYECTOS/2024_claudia_alzheimer/results'\n",
    "data_dir = 'C:/Users/ifiri/Documents/PROYECTOS/2024_claudia_alzheimer/precuneus_nets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY119N3C2TTM3Q56DRGXW7DJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into 2 groups: (1) aC and (2) nC\n",
    "xl = pd.ExcelFile('sujetos_time_series_codes.xlsx')\n",
    "df = xl.parse('datos_demograficos_sanos_schaef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY10V33N677W7V1MZMZYCSNN",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero sacar los indices de los sujetos aC y nC\n",
    "aC_index = df[df['CONDICIÓN']=='aC']\n",
    "nC_index = df[df['CONDICIÓN']=='nC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the data\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Load the time series data\n",
    "ts_data, ts_data_struc, struc_names = process_data(data_dir)\n",
    "\n",
    "# Select the data for the aC group using the indices\n",
    "ts_aC_data = ts_data[aC_index.index]\n",
    "\n",
    "# Select the data for the nC group using the indices\n",
    "ts_nC_data = ts_data[nC_index.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY11G08E98GAJK1QJ6SCVXMY",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT THE GROUP TO ANALYZE\n",
    "ts_data = ts_nC_data\n",
    "group = 'nC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY11C61Z6WV1GQ21MM81JZ84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window the data and compute the correlation matrices\n",
    "structure_names = struc_names.to_list()\n",
    "delta = 8 #number of time points on each window. LB^(-1) = delta * TR (2.2s)\n",
    "corr_matrices = split_into_windows_and_compute_correlation(ts_data, delta)\n",
    "print(corr_matrices.shape)  # Debería ser (62, 62, 57, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example plots and data exploration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXVXTY1HGPBB6ZGCZFJJ3CAA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a specific value\n",
    "subject_id = 'Subject001'\n",
    "timepoint = 1\n",
    "structure = 'atlas.Precuneous'\n",
    "\n",
    "specific_value = ts_data_struc.sel(subject=subject_id, timepoint=timepoint, struc=structure).item()\n",
    "print(f\"The value for {subject_id}, timepoint {timepoint}, structure '{structure}' is {specific_value}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXW0ZNCMKAKCRA925P1EB1MV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heatmap (sns) of a correlation matrix (e.g. the first one) from corr_df and add the x and y labels of the structure_names\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrices[:, :, 0, 0], xticklabels=structure_names, yticklabels=structure_names, cmap='viridis')\n",
    "plt.xlabel('Structures')\n",
    "plt.ylabel('Structures')\n",
    "plt.title('Correlation matrix for the first window of the first subject')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXXYAXR5AEZF000AYW9RQSGE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a panel of figures with the correlation matrices for the first subject and all windows (33 windows) a grid of 6x6 figures\n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(25, 25))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    sns.heatmap(corr_matrices[:, :, 0, i], cmap='viridis', ax=ax)\n",
    "    ax.set_title(f'Window {i+1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXVYW32GPRTRT3350JQ0EF62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a specific structure\n",
    "structure = 'atlas.Precuneous'\n",
    "\n",
    "# Select the data for the specified structure\n",
    "specific_structure_data = ts_data_struc.sel(struc=structure)\n",
    "print(f\"Data for structure '{structure}':\\n\", specific_structure_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTER-PRECUNEUS ANALYSIS: 6 ANALYSIS IN TOTAL\n",
    "(1) precuneus (total) with the rest\n",
    "(2-6) 7Am, 7Pm, 7m, PVC and POS2 with the rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXXY67S3SVW2TFW74TCCPK3X",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the structure\n",
    "structure = 'POS2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXXKX6390M68EH27TKJ5H3SK",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fix one structure and perfom the analysis\n",
    "structure_index = structure_names.index(structure)\n",
    "\n",
    "# Seleccionar todas las estructuras excepto la fijada\n",
    "remaining_indices = [i for i in range(len(structure_names)) if i != structure_index]\n",
    "\n",
    "# Seleccionar los datos correspondientes a la fila de la estructura fijada y las columnas restantes\n",
    "corr_matrices_structure_rows = corr_matrices[remaining_indices,:, :, :]\n",
    "corr_matrices_structure_col = corr_matrices_structure_rows[:,structure_index, :, :]\n",
    "print(corr_matrices_structure_col[:,2,20]) # Debería ser un vector de 62 elementos. El elemento 6 (precuneus) debería tener valor de corr=1. La correlacion de una estructura consigo misma (6,6) es 1.\n",
    "\n",
    "# I want to compute the euclidean distance between all pairs of 33 windows so that i obtain a 33x33 matrix for each subject. \n",
    "# I will have 57 subjects, so the final matrix will be 33x33x57.\n",
    "\n",
    "norm_distances = compute_norm_distances(corr_matrices_structure_col)\n",
    "print(norm_distances.shape)  # Debería ser (33, 33, 57)\n",
    "\n",
    "# Flatten each subject distance matrix to obtain a vector per subject\n",
    "\n",
    "flattened_distances = flatten_distance_matrices(norm_distances)\n",
    "print(flattened_distances.shape)  # Debería ser (57, 1089)\n",
    "\n",
    "# Mean distance per subject\n",
    "mean_distances = np.mean(flattened_distances, axis=1)\n",
    "\n",
    "# Save the mean distances to a CSV file in the main folder and include fixed structure name in the filename\n",
    "filename = f'{group}_inter_analysis_mean_distances_{structure}.csv'\n",
    "np.savetxt(os.path.join(results_dir,filename), mean_distances, delimiter=',')\n",
    "print(f\"Mean distances saved to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRA-PRECUNEUS ANALYSIS: 1 IN TOTAL.\n",
    "7Am, 7Pm, 7m, PCV and POS2 strucs between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXXY6HRBR9XVZJ7M0315PMKZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the 5 structures and find the index of each one\n",
    "strucs =  '7Am', '7Pm', '7m', 'PVC', 'POS2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXXSYQNNSM6TR68CPPYD70T9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fix one structure and perfom the analysis\n",
    "structure_indices = [structure_names.index(s) for s in strucs]\n",
    "\n",
    "# Select the data for the specified structure. The final matrix should be 5x5x57x33\n",
    "corr_matrices_structure_row = corr_matrices[structure_indices, :, :, :]\n",
    "corr_matrices_structure_col = corr_matrices_structure_row[:, structure_indices, :, :]\n",
    "print(corr_matrices_structure_col.shape)  # Debe ser: (5,5,57,33)\n",
    "\n",
    "# Flatten the intra-structure matrices to compute the norm distance between vectors and no between matrices\n",
    "intra_size = corr_matrices_structure_col.shape[0]\n",
    "subjects = corr_matrices_structure_col.shape[2]\n",
    "windows = corr_matrices_structure_col.shape[3]\n",
    "corr_matrices_structure_flat = corr_matrices_structure_col.reshape(intra_size*intra_size, subjects, windows)\n",
    "\n",
    "# I want to compute the euclidean distance between all pairs of 33 windows so that i obtain a 33x33 matrix for each subject. \n",
    "# I will have 57 subjects, so the final matrix will be 33x33x57.\n",
    "\n",
    "norm_distances = compute_norm_distances(corr_matrices_structure_flat)\n",
    "print(norm_distances.shape)  # Debería ser (33, 33, 57)\n",
    "\n",
    "# Flatten each subject distance matrix to obtain a vector per subject\n",
    "\n",
    "flattened_distances = flatten_distance_matrices(norm_distances)\n",
    "print(flattened_distances.shape)  # Debería ser (57, 1089)\n",
    "\n",
    "# Mean distance per subject\n",
    "mean_distances = np.mean(flattened_distances, axis=1)\n",
    "\n",
    "# Save the mean distances to a CSV file in the main folder and include fixed structure name in the filename\n",
    "filename = f'{group}_intra_analysis_mean_distances_5precuneus.csv'\n",
    "np.savetxt(os.path.join(results_dir,filename), mean_distances, delimiter=',')\n",
    "print(f\"Mean distances saved to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-parametric t-test between groups (aC vs. nC): 7 comparisons. (1) intra-5precuneus (6) inter-precuneus, 7Am, 7Pm, 7m, PVC, POS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY2NKPG9887FTBPFQVZCFTBA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file as vector\n",
    "structure = '5precuneus'\n",
    "\n",
    "file_aC = f'aC_intra_analysis_mean_distances_{structure}.csv'\n",
    "file_nC = f'nC_intra_analysis_mean_distances_5precuneus.csv'\n",
    "mean_distances_aC = np.loadtxt(os.path.join(results_dir,file_aC), delimiter=',')\n",
    "mean_distances_nC = np.loadtxt(os.path.join(results_dir,file_nC), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY2PT3J8T83PGWJH1SJ3061B",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a non parametric test to compare the mean distances between the two groups\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "# Assumptions:\n",
    "## (1) Independence: The samples must be independent of each other.\n",
    "## (2) Ordinal or Continuous Data: The data should be at least ordinal (ranked) or continuous.\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p_value = mannwhitneyu(mean_distances_aC, mean_distances_nC, alternative='two-sided')\n",
    "\n",
    "print('Statistics:', stat)\n",
    "print('p-value:', p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY2Q0EG9FN2HYX2QE5MA8HES",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the independent t-test\n",
    "# Assumptions:    \n",
    "## (1) Normality: The data in each group should be approximately normally distributed.\n",
    "## (2) Independence: The samples must be independent of each other.\n",
    "## (3) Homogeneity of Variance: The variances of the two groups should be equal.\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "stat, p_value = ttest_ind(mean_distances_aC, mean_distances_nC,  equal_var=False)\n",
    "print('Statistics:', stat)\n",
    "print('p-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HY2TGAPNKVN18N7QDBM0YDNJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "import os\n",
    "\n",
    "# Directory containing the CSV files\n",
    "results_dir = \"C:/Users/ifiri/Documents/PROYECTOS/2024_claudia_alzheimer/results/\"\n",
    "\n",
    "# Initialize lists to store filenames\n",
    "aC_files = []\n",
    "nC_files = []\n",
    "\n",
    "# Separate filenames into aC and nC lists\n",
    "for filename in os.listdir(results_dir):\n",
    "    if filename.startswith(\"aC\"):\n",
    "        aC_files.append(filename)\n",
    "    elif filename.startswith(\"nC\"):\n",
    "        nC_files.append(filename)\n",
    "\n",
    "# Extract structure names without prefixes and suffixes for matching\n",
    "aC_structures = [filename.split('_')[5].split('.')[0] for filename in aC_files]\n",
    "nC_structures = [filename.split('_')[5].split('.')[0] for filename in nC_files]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Perform Mann-Whitney U test for 5precuneus (intra-analysis)\n",
    "ac_file = \"aC_intra_analysis_mean_distances_5precuneus.csv\"\n",
    "nc_file = \"nC_intra_analysis_mean_distances_5precuneus.csv\"\n",
    "ac_data = pd.read_csv(os.path.join(results_dir, ac_file))\n",
    "nc_data = pd.read_csv(os.path.join(results_dir, nc_file))\n",
    "\n",
    "ac_values = ac_data.iloc[:, 0]\n",
    "nc_values = nc_data.iloc[:, 0]\n",
    "\n",
    "stat, p_value = mannwhitneyu(ac_values, nc_values, alternative='two-sided')\n",
    "\n",
    "results.append({'Structure': '5precuneus', 'U-statistic': stat, 'p-value': p_value, 'Comparison': 'Intra'})\n",
    "\n",
    "# Perform Mann-Whitney U test for each matching structure (inter-analysis)\n",
    "for structure in set(aC_structures) & set(nC_structures):\n",
    "    if structure == '5precuneus':\n",
    "        continue\n",
    "    \n",
    "    aC_file = next(f for f in aC_files if structure in f)\n",
    "    nC_file = next(f for f in nC_files if structure in f)\n",
    "    \n",
    "    # Load data for the current structure\n",
    "    aC_data = pd.read_csv(os.path.join(results_dir, aC_file))\n",
    "    nC_data = pd.read_csv(os.path.join(results_dir, nC_file))\n",
    "\n",
    "    # Assuming the data is in a single column, if there are multiple columns, specify the correct one\n",
    "    aC_values = aC_data.iloc[:, 0]\n",
    "    nC_values = nC_data.iloc[:, 0]\n",
    "\n",
    "    # Perform Mann-Whitney U test\n",
    "    stat, p_value = mannwhitneyu(aC_values, nC_values, alternative='two-sided')\n",
    "\n",
    "    # Append results\n",
    "    results.append({'Structure': structure, 'U-statistic': stat, 'p-value': p_value, 'Comparison': 'Inter'})\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "num_comparisons = len(results_df)\n",
    "bonferroni_alpha = 0.05 / num_comparisons\n",
    "results_df['corrected p-value'] = results_df['p-value'] * num_comparisons\n",
    "\n",
    "# Ensure that corrected p-values do not exceed 1\n",
    "results_df['corrected p-value'] = results_df['corrected p-value'].apply(lambda p: min(p, 1.0))\n",
    "\n",
    "# Determine if the corrected p-value is significant\n",
    "results_df['significant'] = results_df['corrected p-value'] < bonferroni_alpha\n",
    "\n",
    "print('Bonferroni alpha: 0.05/num.comparisons =', bonferroni_alpha)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
